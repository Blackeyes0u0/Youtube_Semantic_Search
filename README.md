---
---
---

# <center> Youtube Semantic Search </center>

---

<center>

![GitHub ë¡œê³ ](README_image/0u0.png)

</center>

#### <center> JoongHyun Shin </center>

<!-- <br> -->
## í”„ë¡œì íŠ¸ ì†Œê°œ

ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë§Œë“¤ê³  ë¯¸ë¦¬ í¬ë¡¤ë§ì„ í†µí•´ì„œ ìœ íŠœë¸Œ ì˜ìƒë“¤ì„ ì„ë² ë”©ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. ì´ë•Œ, ì˜ìƒì„ ì„ë² ë”©ìœ¼ë¡œ ë§Œë“¤ ë•Œ CLIP(ì´ë¯¸ì§€ ì¸ì½”ë”)ê³¼ XCLIP(ë¹„ë””ì˜¤ ì¸ì½”ë”)ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, domain adaptation í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ì„œ PEFT ì¤‘ LoRAë¥¼ ì ìš©í•˜ì—¬ ëª¨ë¸ ì•„í‚¤í…ì³ë¥¼ êµ¬ì„±í•˜ì˜€ê³ , contrastive lossë¡œ ìœ íŠœë¸Œ image-text pair ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ìƒì„±ëœ ì´ë¯¸ì§€(ë¹„ë””ì˜¤) ì„ë² ë”©ë“¤ì„ vector DB(Qdrant)ì— ì €ì¥í•˜ì˜€ê³ , ì‚¬ìš©ìê°€ ë¬¸ì¥ìœ¼ë¡œ ê²€ìƒ‰í•˜ë”ë¼ë„ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ìˆê²Œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ streamlitìœ¼ë¡œ ë°°í¬í•˜ì˜€ìŠµë‹ˆë‹¤.

**ì•„ë˜ streamlitì„ í†µí•œ ë°ëª¨ë²„ì „ì„ ì²´í—˜í•´ë³´ì„¸ìš”!**

<img src="streamlit.gif"/>

## [streamlit ë°ëª¨ë²„ì „](https://youtube-rank.streamlit.app/)


---

# Train

base modelì€ ğŸ¤— Transformersì˜ CLIP,XCLIPì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

### Installation 


```bash
pip install transformers
pip install peft
pip install loralib
pip install wandb
```

## File Structure

```
Youtube-Semantic-Search
â”œâ”€â”€ README.md
â”‚â”€â”€ streamlit-app.py
â”‚â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Data
â”‚  â”œâ”€â”€ VQA
â”‚  â”‚
â”‚  â””â”€â”€ Youtube_thumbnails
â”‚       â”œâ”€â”€ images
â”‚       â””â”€â”€ metadata.csv
â”‚
â”œâ”€â”€ train
â”‚  â”œâ”€â”€ bluebird
â”‚  â”œâ”€â”€ chalk
â”‚  â”œâ”€â”€ cli-spinner
â”‚  â”œâ”€â”€ meow
â”‚  â””â”€â”€ object-assign
â”‚
â”œâ”€â”€ Qdrant
â”‚  â”œâ”€â”€ qdrant_upload.py
â”‚  â”œâ”€â”€ chalk
â”‚  â”œâ”€â”€ cli-spinner
â”‚  â”œâ”€â”€ meow
â”‚  â””â”€â”€ crawling
â”‚     â”œâ”€â”€ bluebird
â”‚     â”œâ”€â”€ chalk
â”‚     â”œâ”€â”€ cli-spinner
â”‚     â””â”€â”€ object-assign
â”‚
â”‚â”€â”€ streamlit-app.py
â”‚â”€â”€ package.json
â””â”€â”€ tree.js
```



# 1. Datasets & DataLoader

<!-- ![Alt text](image-2.png) -->

#### youtube thumbnails data

$I^{(i)}$ : youtube thumbnail Image data $i$
$T^{(i)}$ : youtube Title data $i$

<!-- #### Example 

$I^{(i)}$ : ![Alt text](image-1.png)

$T^{(i)}$ : **Cutest Cats Compilation 2017 | Best Cute Cat Videos Ever** -->


---
# 2. Model & Loss Architecture

<!-- 
![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png) -->

<!-- ![Alt text](image-5.png) -->
![Alt text](image-7.png)

ìœ„ ëª¨ë¸ ì•„í‚¤í…ì³ë¥¼ ë³´ë©´ Latent space ìƒì—ì„œ ì´ë¯¸ì§€ ì„ë² ë”©ê³¼ í…ìŠ¤íŠ¸ ì„ë² ë”©ì˜ ê±°ë¦¬ë¥¼ ê°€ê¹ê²Œ í•˜ëŠ”ê²ƒì„ alignment, ë©€ê²Œí•˜ëŠ”ê²ƒì„ Uniformë¼ê³  ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.

### [model ì„¤ëª…](https://velog.io/@blackeyes0u0/youtube-CLIP-LoRA-SimCSE-%EA%B2%B0%EA%B3%BC)

### [LoRA ë…¼ë¬¸ ë¦¬ë·°](https://velog.io/@blackeyes0u0/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-LoRA-Low-Rank-Adaptation-of-Large-Language-Models)


---


# 3. Objective function

$$
h_i = f(x_i)
$$


$$ 
\mathcal{L_i} = - \log \frac{e^{sim(h_i,h_i^+) / \tau}}{\sum_je^{sim(h_i,h_j)/ \tau}}
$$



$i$ ë²ˆì§¸ ë°ì´í„°ì™€ $N$ê°œì˜ batch_size pair ëŒ€í•´ì„œ ìœ„ì™€ ê°™ì´ í‘œí˜„ í•  ìˆ˜ìˆë‹¤. 

$h_i$ëŠ” ë°ì´í„°ì˜ ì„ë² ë”©ì— í•´ë‹¹í•˜ê³ , $z_i$ëŠ” ê° ë°ì´í„°ì— ê°€í•œ augmentationì— í•´ë‹¹í•œë‹¤. $\tau$ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° temperatureê°’ì´ë‹¤.


<!-- ![Alt text](image-3.png) -->

<!-- ![Alt text](image-6.png) -->

$$
\mathcal{L} = \sum_{i=1}^{N} log \exp^ {-\frac{1}{\tau}  sim(h_i,h_i^+)} (Alignment)
$$

$$
+\sum_{i=1}^{N} log \sum_{j=1 }^{N} \exp^{\frac{1}{\tau} sim(h_i,h_j)} (Uniform)
$$


ì—¬ê¸°ì„œ ë‚˜ì˜¤ëŠ” simì€ similarityì˜ ì•½ìì´ê³ , cosine similarityë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•™ìŠµëœ íŒŒì¼ì€ **huggingface spaceì— ë°ëª¨ ë²„ì „ì„ ì˜¬ë ¤ë†“ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ í´ë¦­**

### [Click](https://huggingface.co/Soran/youtube_CLIP_LoRA_SimCSE)

---

# Vector DB & Deploy

vector DBëŠ” Qdrantë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë¦¬í•˜ì˜€ê³ , streamlit ì‚¬ì´íŠ¸ë¥¼ ì´ìš©í•´ì„œ ë°°í¬í•˜ì˜€ìŠµë‹ˆë‹¤.


---

>ê¸°ì—¬: ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ì„¸ìš”. ì´ëŠ” ë²„ê·¸ ë¦¬í¬íŠ¸, ê¸°ëŠ¥ ì œì•ˆ, ì½”ë“œ ìˆ˜ì • ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


>ì¶”ê°€ ì •ë³´: í”„ë¡œì íŠ¸ì™€ ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê´€ë ¨ ë…¼ë¬¸, ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸, ë°ëª¨ ì˜ìƒ ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

## Reference

##### paper References
- CLIP : https://arxiv.org/abs/2103.00020
- LoRA : https://arxiv.org/abs/2106.09685
- SimCSE : https://arxiv.org/abs/2104.08821
- SimCLR : https://arxiv.org/abs/2002.05709
- XCLIP : https://arxiv.org/abs/2208.02816

##### Blog References
- Qdrant : https://qdrant.tech/documentation/overview/
- LoRA Offical github : https://github.com/microsoft/LoRA
- torchviz : https://github.com/szagoruyko/pytorchviz